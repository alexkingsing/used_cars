{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quiet-watson",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9adf7f631cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# tensorflow imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mself_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cars\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m           \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[1;34m\"Could not find the DLL(s) %r. TensorFlow requires that these DLLs \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;34m\"be installed in a directory that is named in your %%PATH%% \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads"
     ]
    }
   ],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, save_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# setting style\n",
    "plt.style.use(\"seaborn-colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0dd44-603b-4970-84a7-d14526617401",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd68b59-139b-4dcb-ac29-651ec7f85936",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bc0e208-5390-4019-8cd8-a63415144d25",
   "metadata": {},
   "source": [
    "This project was a born from a curiosity question of mine as I prepared for my MBA in the U.S. As many know, cars are the most common method of transportation in the U.S as trains, buses, and other kinds of public transportation vary greatly by state and city.\n",
    "\n",
    "Considering that, I asked myself: \"How much would it cost to buy a car in the U.S?\" I immediately discarded new vehicles because they're substantially more expensive, depreciate rapidly and simply didn't adjust to my budget. The only option was **used vehicles**. \n",
    "\n",
    "The question then changed to: \"How much would it cost to buy a used car in the U.S?\" It's sometimes difficult to find information that one considers both reliable and scalable and that has relevance over time, specially when P2P (Peer-to-Peer) markets are so heterogenous. \n",
    "\n",
    "In light of this, and building on my curiosity about ML / DL, I decided to build a model to **estimate the value / price of a used vehicle in the U.S**.\n",
    "\n",
    "**SCOPE**: \n",
    "* For time reasons I will **exclude** any kind of **image analysis**.\n",
    "* In-depth NLP tasks are not in scope of this analysis, but some tasks may be used for additional information.\n",
    "* Data points such as VIN, which are used in history analysis, will also be excluded.\n",
    "\n",
    "In general, this exercise attempts to create a prediction model with minimal inputs and without complex encodings & transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764079e2-26f0-443c-ae77-facbdc2eb52a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DATA SELECTION, CLEANING & PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0bec98-56cf-45c1-a00b-25206ffdbad4",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004b037-82f7-4fe2-84c5-4cd8d2c9793a",
   "metadata": {},
   "source": [
    "The first thing I'll do after loading the data will be to analyze and discover columns that only have 1 value OR where each value is unique. Excluding geographical coordinates, features such as \"ID\" or otherwise unique identifiers do not assist for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6cabd-5991-4244-b207-1075379e0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading file and info\n",
    "df = pd.read_csv(\"data/vehicles.csv\")\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4364452-0c72-4999-9608-41159a828f1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4b436d1-a278-4dc7-a08a-cb5e3f0e676a",
   "metadata": {},
   "source": [
    "We can observe that **ID** and **URL** are unique for each vehicle posting, so we can go ahead and discard them since they do not provide any useful insights.\n",
    "\n",
    "Additionally, image analysis is not in the scope of this review, so I will also ignore **image_url**.\n",
    "\n",
    "Finally, as mentioned in scope, I will delete VIN, since for the scope for of this project I will not be querying the car's history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94f31a-179e-43af-a770-5732f5320a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting useless columns.\n",
    "df = df.drop(columns = [\"id\", \"url\", \"image_url\", \"VIN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbd355-5300-4e4d-9404-7f0bc05e44aa",
   "metadata": {},
   "source": [
    "Next, I'll analyze and discover missing data points and find out what to do with these columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42d400-a9d5-479d-8355-63d4eeb8efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6ecab-3aa0-45b5-a908-ade6f13c8fef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40216d15-e218-4251-8b4d-b35947fde9cf",
   "metadata": {},
   "source": [
    "Df.info() provides a good insight into the missing information, but let's try a different way to see how much missing data do we really have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8c4f3-2669-4d8d-bf7b-27d9689229a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating all missing data points and normalizing to df size\n",
    "df.isna().sum() * 100 / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee2c06-88fb-4799-8b61-4f333574f120",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac5891a4-32cf-400c-8885-7f2552bc4550",
   "metadata": {},
   "source": [
    "As we can see, columns such as:\n",
    "* County -> 100% missing data\n",
    "* size -> 71.76% missing data\n",
    "\n",
    "have large amounts of missing data that we can outright consider impossible to fix, so we will just delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31301bb6-3d0d-4357-86f7-34f330b71ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll delete the columns with too much missing data to be recoverable\n",
    "df = df.drop(columns = [\"county\", \"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da5413-536e-40f5-81e3-bed792915371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start exploring some of the remaining information to understand what kind of information do we have at hand\n",
    "## In particular, let's start exploring REGION & REGION_URL\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfb3cd-55d4-47a2-a0cb-8cb18279bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 records in region\n",
    "df[\"region\"].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f75cdb-f6dc-4dc4-8b8c-ac12c50cbab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 records in region URL\n",
    "df[\"region_url\"].unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f2d71-8f27-4147-be78-7c763832cf8c",
   "metadata": {},
   "source": [
    "In general, region seems to be related to the seller's location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea66908-028a-4886-b8c1-c6a1d86e4829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
